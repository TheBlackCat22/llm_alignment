Task: SFT
Model: models/Default/gpt2
Dataset: imdb
Seed: 42
OutputDir: output/Run2


DataConfig: 
  only_positive: True
  eval_size: 2500
  test_size: 5000


PromptConfig:
  min_tokens: 18
  max_tokens: 24
  

SFTConfig:
  per_device_train_batch_size: 8
  per_device_eval_batch_size: 16
  num_train_epochs: 10  
  logging_steps: 100
  save_steps: 500
  eval_steps: 100


GenerationConfig:
  do_sample: True
  top_k: 50
  min_length: 48
  max_new_tokens: 48


MetricConfig:
  RewardModel: models/Default/distilbert
  label_idx: 1