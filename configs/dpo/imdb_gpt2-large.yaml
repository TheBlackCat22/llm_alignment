Task: DPO
Model: models/SFT/gpt2-large
Dataset: imdb
Seed: 42
OutputDir: output/Run3
DatasetDir: datasets


DataConfig: 
  only_positive: False
  eval_size: 2500
  test_size: 5000


PromptConfig:
  min_tokens: 2
  max_tokens: 8


DPOConfig:
  beta: 0.1
  learning_rate: 1.0e-06
  warmup_steps: 150
  num_train_epochs: 3
  per_device_train_batch_size: 4
  per_device_eval_batch_size: 8
  logging_steps: 10
  save_steps: 500
  eval_steps: 100


GenerationConfig:
  do_sample: True
  top_k: 0.0
  min_length: -1
  max_new_tokens: 32
  top_p: 1.0


RewardConfig:
  RewardModel: models/Default/siebert
  label_idx: 1


MetricConfig:
  RewardModel: models/Default/siebert
  label_idx: 1