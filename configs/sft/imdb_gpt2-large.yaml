Task: 'SFT'
Model: 'gpt2-large'
Dataset: 'imdb'
Seed: 10
OutputDir: "output/Run2"


DataConfig: 
  only_positive: True
  eval_ratio: 0.1
  test_size: 5000
  

SFTConfig:
  per_device_eval_batch_size: 16
  num_train_epochs: 2  
  report_to: "tensorboard"
  logging_steps: 100
  save_steps: 500
  save_total_limit: 1
  save_only_model: True
  evaluation_strategy: 'steps'
  eval_steps: 100
  load_best_model_at_end: True
  metric_for_best_model: "eval_loss"


PromptConfig:
  min_tokens: 2
  max_tokens: 8


GenerationConfig:
  do_sample: True
  top_k: 50
  min_length: -1
  max_new_tokens: 48


MetricConfig:
  RewardModel: siebert
  label_idx: 1